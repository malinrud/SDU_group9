{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Summer Course - Exercise 4\n",
    "**Date:** Friday 9-8-2024\n",
    "\n",
    "This notebook solves Exercise 4 of the Deep Learning Summer Course, where we build a Convolutional Neural Network (CNN) to recognize numbers in pictures from the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Download the MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# a. Output the dimensions of train and test dataset and the size of the images\n",
    "print(f\"Train dataset size: {train_dataset.data.shape}\")\n",
    "print(f\"Test dataset size: {test_dataset.data.shape}\")\n",
    "print(f\"Image size: {train_dataset.data[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Plot the digit distribution using a bar histogram\n",
    "train_labels = train_dataset.targets.numpy()\n",
    "sns.countplot(x=train_labels)\n",
    "plt.title('Distribution of Digits in MNIST Train Dataset')\n",
    "plt.xlabel('Digits')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Design the CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Train the CNN and achieve at least 95% accuracy\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "    print('Finished Training')\n",
    "    torch.save(model.state_dict(), 'cnn_model.pth')\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the 10000 test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Plot the first convolutional layer filters before and after training\n",
    "def plot_filters(layer):\n",
    "    filters = layer.weight.data.numpy()\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(10, 5))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < filters.shape[0]:\n",
    "            ax.imshow(filters[i, 0, :, :], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot filters before training\n",
    "model_untrained = CNN()\n",
    "plot_filters(model_untrained.conv1)\n",
    "\n",
    "# Plot filters after training\n",
    "plot_filters(model.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Feed the first convolutional layer an image and plot its activations\n",
    "def plot_activations(layer, image):\n",
    "    activations = layer(image.unsqueeze(0)).detach().numpy()\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(10, 5))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < activations.shape[1]:\n",
    "            ax.imshow(activations[0, i, :, :], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sample_image, _ = test_dataset[0]\n",
    "plot_activations(model.conv1, sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Plot some incorrectly labelled data points\n",
    "incorrect_examples = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        for i in range(len(labels)):\n",
    "            if predicted[i] != labels[i]:\n",
    "                incorrect_examples.append((images[i], predicted[i], labels[i]))\n",
    "\n",
    "# Plot a few incorrect examples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 4))\n",
    "for i, (image, pred, label) in enumerate(incorrect_examples[:5]):\n",
    "    axes[i].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f'Pred: {pred.item()}\\nTrue: {label.item()}')\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "In this exercise, we successfully built and trained a Convolutional Neural Network (CNN) to recognize digits in the MNIST dataset. The model achieved over 95% accuracy on the test set, and we explored the filters of the first convolutional layer, as well as analyzed some incorrectly classified images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
